{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b650c9ea7e63bbb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:45:52.427053Z",
     "start_time": "2024-12-07T22:41:31.323333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m21:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mUsing device: mps\u001b[0m\n",
      "\u001b[32m21:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mInitializing ChessDataset\u001b[0m\n",
      "\u001b[32m21:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mRepository Youcef/chessGames already exists\u001b[0m\n",
      "\u001b[32m21:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mDataset already exists, loading...\u001b[0m\n",
      "\u001b[32m21:42:28 - chessAI - INFO\u001b[0m \u001b[1;37mSuccessfully initialized ChessDataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset.chess_dataframe import ChessDataFrame, Sizes\n",
    "from logging_config import setup_logging\n",
    "\n",
    "# Setup logging\n",
    "logger = setup_logging()\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# I need to make csv batches of data and uploads it to huggingface\n",
    "dataset = ChessDataFrame(size=Sizes.extra_smol)\n",
    "logger.info(\"Successfully initialized ChessDataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ddbb98300acfd5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:47:19.551028Z",
     "start_time": "2024-12-07T22:47:19.531306Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result</th>\n",
       "      <th>WhiteElo</th>\n",
       "      <th>BlackElo</th>\n",
       "      <th>Player</th>\n",
       "      <th>Time</th>\n",
       "      <th>Eval</th>\n",
       "      <th>Raw Eval</th>\n",
       "      <th>Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1288</td>\n",
       "      <td>1287</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.9833333333333333, 1.0, ...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.53, 0.17, 0.27, 0.25, 0.3...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.53, 0.17, 0.27, 0.25, 0.3...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1</td>\n",
       "      <td>1844</td>\n",
       "      <td>1922</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9833333333333333, 1.0, 0.96666666...</td>\n",
       "      <td>[0.15, 0.25, 0.22, 0.31, 0.21, 0.34, 0.37, 0.3...</td>\n",
       "      <td>[0.15, 0.25, 0.22, 0.31, 0.21, 0.34, 0.37, 0.3...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0</td>\n",
       "      <td>1816</td>\n",
       "      <td>1822</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9833333333333333, 1.0, 0.96666666...</td>\n",
       "      <td>[-0.28, 0.33, -0.41, -0.41, -0.5, -0.47, -1.89...</td>\n",
       "      <td>[-0.28, 0.33, -0.41, -0.41, -0.5, -0.47, -1.89...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/7P/8/PPPPPPP1/RNBQKBNR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>1111</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9666666666666667, 1.0, 0.93333333...</td>\n",
       "      <td>[0.16, 0.23, -0.58, 0.96, -0.53, -0.56, -0.56,...</td>\n",
       "      <td>[0.16, 0.23, -0.58, 0.96, -0.53, -0.56, -0.56,...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>0</td>\n",
       "      <td>1350</td>\n",
       "      <td>1324</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9833333333333333, 0.9666666666666...</td>\n",
       "      <td>[0.15, 0.21, -0.45, 0.16, 0.0, 2.14, -0.9, -0....</td>\n",
       "      <td>[0.15, 0.21, -0.45, 0.16, 0.0, 2.14, -0.9, -0....</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "      <td>1454</td>\n",
       "      <td>1440</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9833333333333333, 0.9833333333333...</td>\n",
       "      <td>[0.16, 0.23, 0.19, 0.53, 0.07, 0.29, -0.16, 0....</td>\n",
       "      <td>[0.16, 0.23, 0.19, 0.53, 0.07, 0.29, -0.16, 0....</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>2048</td>\n",
       "      <td>1916</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9833333333333333, 0.98333333...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.53, 0.28, 0.5, 0.49, 1.16...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.53, 0.28, 0.5, 0.49, 1.16...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "      <td>2325</td>\n",
       "      <td>2283</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9833333333333333, 1.0, 0.95,...</td>\n",
       "      <td>[0.16, 0.23, 0.2, 0.39, 0.13, 0.19, 0.17, 0.24...</td>\n",
       "      <td>[0.16, 0.23, 0.2, 0.39, 0.13, 0.19, 0.17, 0.24...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>1123</td>\n",
       "      <td>1924</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9833333333333333, 1.0, 0.966...</td>\n",
       "      <td>[0.15, 0.26, 0.33, 0.27, -0.97, 0.35, 0.29, 0....</td>\n",
       "      <td>[0.15, 0.26, 0.33, 0.27, -0.97, 0.35, 0.29, 0....</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>1074</td>\n",
       "      <td>1062</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...</td>\n",
       "      <td>[1.0, 1.0, 0.9833333333333333, 1.0, 0.98333333...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.19, 0.12, 0.64, 0.13, 0.3...</td>\n",
       "      <td>[0.15, 0.21, 0.11, 0.19, 0.12, 0.64, 0.13, 0.3...</td>\n",
       "      <td>[rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Result  WhiteElo  BlackElo  \\\n",
       "29        1      1288      1287   \n",
       "535       1      1844      1922   \n",
       "695       0      1816      1822   \n",
       "557       1      1024      1111   \n",
       "836       0      1350      1324   \n",
       "..      ...       ...       ...   \n",
       "106       0      1454      1440   \n",
       "270       1      2048      1916   \n",
       "860       1      2325      2283   \n",
       "435       0      1123      1924   \n",
       "102       1      1074      1062   \n",
       "\n",
       "                                                Player  \\\n",
       "29   [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "535  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "695  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "557  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "836  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "..                                                 ...   \n",
       "106  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "270  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "860  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "435  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "102  [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, ...   \n",
       "\n",
       "                                                  Time  \\\n",
       "29   [1.0, 1.0, 1.0, 1.0, 0.9833333333333333, 1.0, ...   \n",
       "535  [1.0, 1.0, 0.9833333333333333, 1.0, 0.96666666...   \n",
       "695  [1.0, 1.0, 0.9833333333333333, 1.0, 0.96666666...   \n",
       "557  [1.0, 1.0, 0.9666666666666667, 1.0, 0.93333333...   \n",
       "836  [1.0, 1.0, 0.9833333333333333, 0.9666666666666...   \n",
       "..                                                 ...   \n",
       "106  [1.0, 1.0, 0.9833333333333333, 0.9833333333333...   \n",
       "270  [1.0, 1.0, 1.0, 0.9833333333333333, 0.98333333...   \n",
       "860  [1.0, 1.0, 1.0, 0.9833333333333333, 1.0, 0.95,...   \n",
       "435  [1.0, 1.0, 1.0, 0.9833333333333333, 1.0, 0.966...   \n",
       "102  [1.0, 1.0, 0.9833333333333333, 1.0, 0.98333333...   \n",
       "\n",
       "                                                  Eval  \\\n",
       "29   [0.15, 0.21, 0.11, 0.53, 0.17, 0.27, 0.25, 0.3...   \n",
       "535  [0.15, 0.25, 0.22, 0.31, 0.21, 0.34, 0.37, 0.3...   \n",
       "695  [-0.28, 0.33, -0.41, -0.41, -0.5, -0.47, -1.89...   \n",
       "557  [0.16, 0.23, -0.58, 0.96, -0.53, -0.56, -0.56,...   \n",
       "836  [0.15, 0.21, -0.45, 0.16, 0.0, 2.14, -0.9, -0....   \n",
       "..                                                 ...   \n",
       "106  [0.16, 0.23, 0.19, 0.53, 0.07, 0.29, -0.16, 0....   \n",
       "270  [0.15, 0.21, 0.11, 0.53, 0.28, 0.5, 0.49, 1.16...   \n",
       "860  [0.16, 0.23, 0.2, 0.39, 0.13, 0.19, 0.17, 0.24...   \n",
       "435  [0.15, 0.26, 0.33, 0.27, -0.97, 0.35, 0.29, 0....   \n",
       "102  [0.15, 0.21, 0.11, 0.19, 0.12, 0.64, 0.13, 0.3...   \n",
       "\n",
       "                                              Raw Eval  \\\n",
       "29   [0.15, 0.21, 0.11, 0.53, 0.17, 0.27, 0.25, 0.3...   \n",
       "535  [0.15, 0.25, 0.22, 0.31, 0.21, 0.34, 0.37, 0.3...   \n",
       "695  [-0.28, 0.33, -0.41, -0.41, -0.5, -0.47, -1.89...   \n",
       "557  [0.16, 0.23, -0.58, 0.96, -0.53, -0.56, -0.56,...   \n",
       "836  [0.15, 0.21, -0.45, 0.16, 0.0, 2.14, -0.9, -0....   \n",
       "..                                                 ...   \n",
       "106  [0.16, 0.23, 0.19, 0.53, 0.07, 0.29, -0.16, 0....   \n",
       "270  [0.15, 0.21, 0.11, 0.53, 0.28, 0.5, 0.49, 1.16...   \n",
       "860  [0.16, 0.23, 0.2, 0.39, 0.13, 0.19, 0.17, 0.24...   \n",
       "435  [0.15, 0.26, 0.33, 0.27, -0.97, 0.35, 0.29, 0....   \n",
       "102  [0.15, 0.21, 0.11, 0.19, 0.12, 0.64, 0.13, 0.3...   \n",
       "\n",
       "                                                 Board  \n",
       "29   [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "535  [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "695  [rnbqkbnr/pppppppp/8/8/7P/8/PPPPPPP1/RNBQKBNR ...  \n",
       "557  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...  \n",
       "836  [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "..                                                 ...  \n",
       "106  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...  \n",
       "270  [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "860  [rnbqkbnr/pppppppp/8/8/3P4/8/PPP1PPPP/RNBQKBNR...  \n",
       "435  [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "102  [rnbqkbnr/pppppppp/8/8/4P3/8/PPPP1PPP/RNBQKBNR...  \n",
       "\n",
       "[800 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c5b1415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:04:21.245094Z",
     "start_time": "2024-12-08T00:04:18.292404Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.dataset.helpers import board_fen_to_image\n",
    "\n",
    "def arr_to_imgs(arr):\n",
    "    return torch.tensor(np.array([board_fen_to_image(x) for x in arr]), dtype=torch.float32)\n",
    "\n",
    "def afloat(arr):\n",
    "    return [float(x) for x in arr]\n",
    "\n",
    "train_X = dataset.df_train[\"Board\"].apply(arr_to_imgs).to_numpy()\n",
    "test_X = dataset.df_test[\"Board\"].apply(arr_to_imgs).to_numpy()\n",
    "test_Y = dataset.df_test[\"Result\"].to_numpy()\n",
    "train_Y = dataset.df_train[\"Result\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f94d4d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36108131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d73f2e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:04:23.415170Z",
     "start_time": "2024-12-08T00:04:23.165089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAHqCAYAAADrpwd3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdiklEQVR4nO3dd5hU1fk48Hdpy1KWIiAQaYJBpSg2RFQ0omIvsSFRsMdgbDFRzDcqNvSrscQYNMaAGiv+bElUBANqjBpFMHYFaSpKbHRR4Pz+8GG+jMvA7rC7s8Dn8zz30Tlz7r3vnLkzvLycObcopZQCAAAAAAAoo1ahAwAAAAAAgJpKER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQAAAAAgB0V0AAAAAADIQREdKtkll1wSRUVF1XKuPfbYI/bYY4/M44kTJ0ZRUVE8+OCD1XL+IUOGRMeOHavlXPlauHBhnHzyydG6desoKiqKs88+u9AhlVGd18zqfP86omqtWLEiunfvHldccUW1nnddPq+Fvkaryy233BLt27ePpUuXFjoUAGoIuX3NIrdfO7l99SpUbl/Tff7559GwYcN4/PHHCx0KVBpFdFiD0aNHR1FRUWarX79+tG3bNvbdd9/43e9+FwsWLKiU83z88cdxySWXxJQpUyrleJWpJsdWHldeeWWMHj06Tj/99LjrrrviuOOOy9m3Y8eOWe/3qtuAAQOqMerK99Zbb8Ull1wSM2bMKHQoWWbMmBEnnHBCdO7cOerXrx+tW7eO3XffPS6++OJCh1Zl7r333pg9e3acccYZERE5r7nvbxMnTixs4AX017/+Nfr16xetWrWKBg0axOabbx5HHXVUPPnkk3kd78orr4xHHnmkTPuQIUPim2++iVtvvXUdIwagJpLb1+zYykNu/x25fc1RyNx+8eLFcckll1ToWJX9Hj3++ONxySWXlGnfZJNN4uSTT47f/OY3eR0XaqKilFIqdBBQU40ePTpOOOGEuPTSS6NTp07x7bffxieffBITJ06McePGRfv27eOxxx6Lnj17ZvZZtmxZLFu2LOrXr1/u87zyyiux4447xqhRo2LIkCHl3u+bb76JiIh69epFxHezVfbcc88YM2ZMHHHEEeU+Tr6xffvtt7FixYooLi6ulHNVhZ133jnq1KkT//znP9fat2PHjtGsWbP4xS9+Uea5tm3bxo9+9KOqCDEuueSSGD58eFTl1/GDDz4YRx55ZEyYMKHMzJTvX0fVZerUqbHjjjtGSUlJnHjiidGxY8eYM2dOvPrqq/HEE0/E119/Xa3xVJdtt902evfunSnU/uUvf8l6/s4774xx48bFXXfdldW+9957x6abbpr3edfl85rP91plufbaa+OXv/xl9OvXLw455JBo0KBBTJ06NcaPHx/bbLNNjB49usLHbNSoURxxxBGr3ff888+P+++/P6ZPn75RzL4H2JjI7eX2K8ntK5/cvnpz+4iIzz77LFq2bBkXX3zxagvZ31cV79EZZ5wRN99882qv97fffju23nrrePrpp6vs8wbVqU6hA4D1wX777Rc77LBD5vGwYcPiH//4Rxx44IFx8MEHx9tvvx0lJSUREVGnTp2oU6dqP1qLFy+OBg0aVHti9H1169Yt6PnLY+7cubH11luXu/8PfvCD+MlPflKFEdU8hbqOrr/++li4cGFMmTIlOnTokPXc3LlzqzWWRYsWRcOGDav8PJMnT47XXnstfvvb32bavn+9vfjiizFu3Li1XocrvwfKa10+r9XxvbY6y5Yti8suuyz23nvveOqpp8o8XxXXyVFHHRX/+7//GxMmTJDsA2yg5ParJ7ffMMjt18/cvjpU93u01VZbRffu3WP06NHyajYIlnOBPP3oRz+K3/zmNzFz5sysf21e3Rp448aNi1133TWaNm0ajRo1iq5du8aFF14YEd/NMNlxxx0jIuKEE07I/Lxr5QzJPfbYI7p37x6TJk2K3XffPRo0aJDZN9d6d8uXL48LL7wwWrduHQ0bNoyDDz44Zs+endWnY8eOq50Zs+ox1xbb6tZNXLRoUfziF7+Idu3aRXFxcXTt2jWuvfbaMv8yXVRUFGeccUY88sgj0b179yguLo5u3bqVe3mGuXPnxkknnRSbbrpp1K9fP7bZZpu44447Ms+vXENy+vTp8fe//z0T+7r+5PHaa6+NoqKimDlzZpnnhg0bFvXq1Ysvv/wyIiKee+65OPLII6N9+/ZRXFwc7dq1i3POOSeWLFmyxnPMmDEja5xXVVRUlDXLYObMmfGzn/0sunbtGiUlJbHJJpvEkUcemfU6R48eHUceeWREROy5555lfkK4uutobeO7apzXXntt/PGPf4zOnTtHcXFx7LjjjvHyyy+v8TVGREybNi0222yzMglcRESrVq3KtD3xxBPRr1+/aNy4cZSWlsaOO+4Y99xzT1afMWPGxPbbbx8lJSXRokWL+MlPfhIfffRRVp8hQ4ZEo0aNYtq0abH//vtH48aNY9CgQRHx3ZqGN9xwQ3Tr1i3q168fm266aZx22mmZ93SlV155Jfbdd99o0aJFlJSURKdOneLEE09c62t+5JFHol69erH77ruvte+q1vQ98Oijj8YBBxwQbdu2jeLi4ujcuXNcdtllsXz58jKve9XPa0Xev9V9r1XkMzxx4sTYYYcdon79+tG5c+e49dZby7Ve6GeffRbz58+Pvn37rvb5718nS5cujYsvvji6dOmS+cz96le/ylrjvKioKBYtWhR33HFH5rOw6nfh9ttvH82bN49HH310jbEBsGGR28vtv09uL7dfm3xz+8qIa8aMGdGyZcuIiBg+fHjmOljTjPR83qPddtstGjZsGI0bN44DDjgg3nzzzczzQ4YMiZtvvjkispexWdXee+8df/3rX6v0lxlQXcxEh3Vw3HHHxYUXXhhPPfVUnHLKKavt8+abb8aBBx4YPXv2jEsvvTSKi4tj6tSp8fzzz0fEd/86e+mll8ZFF10Up556auy2224REbHLLrtkjvH555/HfvvtF8ccc0z85Cc/WevPvq644oooKiqK888/P+bOnRs33HBD9O/fP6ZMmZKZVVMe5YltVSmlOPjgg2PChAlx0kknxbbbbhtjx46NX/7yl/HRRx/F9ddfn9X/n//8Zzz00EPxs5/9LBo3bhy/+93v4sc//nHMmjUrNtlkk5xxLVmyJPbYY4+YOnVqnHHGGdGpU6cYM2ZMDBkyJL766qs466yzYquttoq77rorzjnnnNhss80yP+NcmWjk8u2338Znn31Wpr1hw4ZRUlISRx11VPzqV7+KBx54IH75y19m9XnggQdin332iWbNmkXEd0nf4sWL4/TTT49NNtkk/v3vf8dNN90UH374YYwZM2aNcZTXyy+/HP/617/imGOOic022yxmzJgRI0eOjD322CPeeuutaNCgQey+++5x5plnxu9+97u48MILY6uttoqIyPz3+8ozvqu65557YsGCBXHaaadFUVFR/O///m8cfvjh8cEHH6xxRlOHDh1i/Pjx8Y9//GOtMxNGjx4dJ554YnTr1i2GDRsWTZs2jcmTJ8eTTz4Zxx57bKbPCSecEDvuuGOMGDEiPv3007jxxhvj+eefj8mTJ0fTpk0zx1u2bFnsu+++seuuu8a1116bmdF92mmnZY5z5plnxvTp0+P3v/99TJ48OZ5//vmoW7duzJ07N/bZZ59o2bJlXHDBBdG0adOYMWNGPPTQQ2t9v/71r39F9+7d85rplet7YPTo0dGoUaM499xzo1GjRvGPf/wjLrroopg/f35cc801az1uvu9fRPk+w5MnT44BAwZEmzZtYvjw4bF8+fK49NJL1/pZjPgumS8pKYm//vWv8fOf/zyaN2+es++KFSvi4IMPjn/+859x6qmnxlZbbRWvv/56XH/99fHee+9l1kC/66674uSTT46ddtopTj311IiI6Ny5c9axtttuu8x3NAAbD7l9Nrm93F5uv2b55vaVEVfLli1j5MiRcfrpp8dhhx0Whx9+eERE1nJU31eR9+iuu+6KwYMHx7777htXX311LF68OEaOHBm77rprTJ48OTp27BinnXZafPzxx6tdrmal7bffPq6//vp48803o3v37hUaJ6hxEpDTqFGjUkSkl19+OWefJk2apF69emUeX3zxxWnVj9b111+fIiL997//zXmMl19+OUVEGjVqVJnn+vXrlyIi3XLLLat9rl+/fpnHEyZMSBGRfvCDH6T58+dn2h944IEUEenGG2/MtHXo0CENHjx4rcdcU2yDBw9OHTp0yDx+5JFHUkSkyy+/PKvfEUcckYqKitLUqVMzbRGR6tWrl9X22muvpYhIN910U5lzreqGG25IEZH+8pe/ZNq++eab1KdPn9SoUaOs196hQ4d0wAEHrPF4q/aNiNVuI0aMyPTr06dP2n777bP2/fe//50iIt15552ZtsWLF5c5x4gRI1JRUVGaOXNmpu3718z06dNzjnlEpIsvvniN53jhhRfKxDJmzJgUEWnChAll+n//PS/v+K6Mc5NNNklffPFFpu+jjz6aIiL99a9/LXOuVb3xxhuppKQkRUTadttt01lnnZUeeeSRtGjRoqx+X331VWrcuHHq3bt3WrJkSdZzK1asyMTXqlWr1L1796w+f/vb31JEpIsuuijTNnjw4BQR6YILLsg61nPPPZciIt19991Z7U8++WRW+8MPP7zW74VcNttss/TjH/94jX2GDh2adT2ktObvgdVdA6eddlpq0KBB+vrrrzNt3/+8VuT9+/41mlL5P8MHHXRQatCgQfroo48ybe+//36qU6dOmWOuzkUXXZQiIjVs2DDtt99+6YorrkiTJk0q0++uu+5KtWrVSs8991xW+y233JIiIj3//POZtoYNG672+2+lU089NZWUlKw1NgDWL3J7ub3c/jty+8Ll9pUZ13//+98y19CalPc9WrBgQWratGk65ZRTsto/+eST1KRJk6z21f3dZVX/+te/UkSk+++/v1wxQk1mORdYR40aNYoFCxbkfH7lv5A/+uijsWLFirzOUVxcHCeccEK5+x9//PHRuHHjzOMjjjgi2rRpE48//nhe5y+vxx9/PGrXrh1nnnlmVvsvfvGLSCnFE088kdXev3//rBmgPXv2jNLS0vjggw/Wep7WrVvHwIEDM21169aNM888MxYuXBjPPPNM3q+hd+/eMW7cuDLbquc6+uijY9KkSTFt2rRM2/333x/FxcVxyCGHZNpWnRm0aNGi+Oyzz2KXXXaJlFJMnjw57xhXteo5vv322/j888+jS5cu0bRp03j11VfzOmZFx/foo4/OzNCJiMysprW9j926dYspU6bET37yk5gxY0bceOONceihh8amm24at912W6bfuHHjYsGCBXHBBReUuanXyp8LvvLKKzF37tz42c9+ltXngAMOiC233DL+/ve/lzn/6aefnvV4zJgx0aRJk9h7773js88+y2zbb799NGrUKCZMmBAR//eZ/tvf/hbffvvtGl/j933++edZY1URub4HVr0GFixYEJ999lnstttusXjx4njnnXfWetx837+ItX+Gly9fHuPHj49DDz002rZtm+nXpUuX2G+//dZ6/Ijvfp56zz33RK9evWLs2LHx61//OrbffvvYbrvt4u233870GzNmTGy11Vax5ZZbZr1/K2fZrHz/yqNZs2axZMmSWLx4cbn3AWDDILf/P3J7uX2E3H5N8sntqyOuXCryHn311VcxcODArBhr164dvXv3rnBeHRGr/UUIrG8U0WEdLVy4MCup/b6jjz46+vbtGyeffHJsuummccwxx8QDDzxQoaT7Bz/4QYVuELPFFltkPS4qKoouXbqs85qBazNz5sxo27ZtmfFY+dPC76812L59+zLHaNasWZm14FZ3ni222CJq1cr+Cst1nopo0aJF9O/fv8y26rpxRx55ZNSqVSvuv//+iPjup65jxoyJ/fbbL0pLSzP9Zs2aFUOGDInmzZtHo0aNomXLltGvX7+IiJg3b17eMa5qyZIlcdFFF2XWqWzRokW0bNkyvvrqq7zPUdHx/f77uDJRWtv7GBHxwx/+MO6666747LPP4j//+U9ceeWVUadOnTj11FNj/PjxERGZv9Cs6ed/K2Pq2rVrmee23HLLMjHXqVMnNttss6y2999/P+bNmxetWrWKli1bZm0LFy7M3GynX79+8eMf/ziGDx8eLVq0iEMOOSRGjRqVte72mqQ81wPM9T3w5ptvxmGHHRZNmjSJ0tLSaNmyZebGReW5Btbl/VvbZ3ju3LmxZMmS6NKlS5l+q2vLZeDAgfHcc8/Fl19+GU899VQce+yxMXny5DjooIPi66+/jojv3r8333yzzHv3wx/+MBNLea18j9a2ZjsAGx65/f+R28vtI+T2a1PR3L664sqlPO/R+++/HxHf3Svi+zE+9dRT8mo2WtZEh3Xw4Ycfxrx589ZYDCopKYlnn302JkyYEH//+9/jySefjPvvvz9+9KMfxVNPPRW1a9de63kqstZheeX6Q2z58uXliqky5DpPvkXG6tK2bdvYbbfd4oEHHogLL7wwXnzxxZg1a1ZcffXVmT7Lly+PvffeO7744os4//zzY8stt4yGDRvGRx99FEOGDFnjX7TW9N58389//vMYNWpUnH322dGnT59o0qRJFBUVxTHHHJP37KiKqoz3sXbt2tGjR4/o0aNH9OnTJ/bcc8+4++67o3///pUVZpbi4uIyf5FYsWJFtGrVKu6+++7V7rNyzc2ioqJ48MEH48UXX4y//vWvMXbs2DjxxBPjt7/9bbz44ovRqFGjnOfdZJNNyvUXkNVZ3ffAV199Ff369YvS0tK49NJLo3PnzlG/fv149dVX4/zzzy/XNbAu7191f4ZLS0tj7733jr333jvq1q0bd9xxR7z00kvRr1+/WLFiRfTo0SOuu+661e7brl27cp/nyy+/jAYNGlTJdy8ANZfcft3I7VdPbi+3r+64ymNN79HKa+2uu+6K1q1bl9m3Tp3ylxJXjk+LFi3WKV6oCRTRYR2svHnGvvvuu8Z+tWrVir322iv22muvuO666+LKK6+MX//61zFhwoTo379/pf+r7Mp/OV4ppRRTp07NuslIs2bN4quvviqz78yZM2PzzTfPPK5IbCtvVLJgwYKsGSsrl5RY3V3A89GhQ4f4z3/+EytWrMhKlir7PGty9NFHx89+9rN499134/77748GDRrEQQcdlHn+9ddfj/feey/uuOOOOP744zPt48aNW+uxV872+P77s7pZOA8++GAMHjw4fvvb32bavv766zL7VvR9LOT47rDDDhERMWfOnIj4v5s+vvHGGzn/UrsypnfffbfMTXLefffdcsXcuXPnGD9+fPTt27dcf7ndeeedY+edd44rrrgi7rnnnhg0aFDcd999cfLJJ+fcZ8stt4zp06ev9djlNXHixPj888/joYceit133z3TXpnnWBetWrWK+vXrx9SpU8s8t7q2ithhhx3ijjvuyLpOXnvttdhrr73Wer2v7fnp06fnvDkXABsuuX02ub3cvjLI7asursr6rsn1HrVq1Wqt//BRnrw6IveNb2F9YjkXyNM//vGPuOyyy6JTp04xaNCgnP2++OKLMm3bbrttRETmp1gNGzaMiLKJVb7uvPPOrLUcH3zwwZgzZ07WGsSdO3eOF198Mb755ptM29/+9reYPXt21rEqEtv+++8fy5cvj9///vdZ7ddff30UFRWVew3k8pznk08+yfzkMuK7O7LfdNNN0ahRo8zPKqvSj3/846hdu3bce++9MWbMmDjwwAMzYxXxfzM4Vp2xkVKKG2+8ca3HLi0tjRYtWsSzzz6b1f6HP/yhTN/atWuXmRVy0003lZnZUtH3sTrG97nnnlvt+n4r1/dc+fPNffbZJxo3bhwjRozILN2x0srXvsMOO0SrVq3illtuyfqJ4xNPPBFvv/12HHDAAWuN56ijjorly5fHZZddVua5ZcuWZcbuyy+/LDPm3/9M59KnT59444031vlnmCut7jr75ptvVnutFELt2rWjf//+8cgjj8THH3+caZ86dWqZdVRXZ/HixfHCCy+s9rmV+6+8To466qj46KOPstZzXGnJkiWxaNGizOOGDRuu8bPw6quvxi677LLW+ADYcMjty5Lby+0rQm5fPpUZV4MGDSKi/N815X2P9t133ygtLY0rr7xytf3/+9//Zv5/bdfipEmTokmTJtGtW7dyxQg1mZnoUA5PPPFEvPPOO7Fs2bL49NNP4x//+EeMGzcuOnToEI899liZG6Ks6tJLL41nn302DjjggOjQoUPMnTs3/vCHP8Rmm20Wu+66a0R8l/Q2bdo0brnllmjcuHE0bNgwevfuHZ06dcor3ubNm8euu+4aJ5xwQnz66adxww03RJcuXeKUU07J9Dn55JPjwQcfjAEDBsRRRx0V06ZNi7/85S9ZNwOqaGwHHXRQ7LnnnvHrX/86ZsyYEdtss0089dRT8eijj8bZZ59d5tj5OvXUU+PWW2+NIUOGxKRJk6Jjx47x4IMPxvPPPx833HDDGtexXJuPPvoo/vKXv5Rpb9SoURx66KGZx61atYo999wzrrvuuliwYEEcffTRWf233HLL6Ny5c5x33nnx0UcfRWlpafy///f/yv1zv5NPPjmuuuqqOPnkk2OHHXaIZ599Nt57770y/Q488MC46667okmTJrH11lvHCy+8EOPHj49NNtkkq9+2224btWvXjquvvjrmzZsXxcXF8aMf/ShatWpV5phVOb6ruvrqq2PSpElx+OGHZ2ZSvfrqq3HnnXdG8+bN4+yzz46I7/7icf3118fJJ58cO+64Yxx77LHRrFmzeO2112Lx4sVxxx13RN26dePqq6+OE044Ifr16xcDBw6MTz/9NG688cbo2LFjnHPOOWuNp1+/fnHaaafFiBEjYsqUKbHPPvtE3bp14/33348xY8bEjTfeGEcccUTccccd8Yc//CEOO+yw6Ny5cyxYsCBuu+22KC0tjf3333+N5zjkkEPisssui2eeeSb22WefdR7DXXbZJZo1axaDBw+OM888M4qKiuKuu+6qUT+bvuSSS+Kpp56Kvn37xumnn575y3j37t1jypQpa9x38eLFscsuu8TOO+8cAwYMiHbt2sVXX30VjzzySDz33HNx6KGHRq9evSIi4rjjjosHHnggfvrTn8aECROib9++sXz58njnnXfigQceiLFjx2Zm2Wy//fYxfvz4uO6666Jt27bRqVOn6N27d0R8l+h/8cUXWTcSA2DDIreX28vt5faFyu0rM66SkpLYeuut4/77748f/vCH0bx58+jevXvO9eYr8h6NHDkyjjvuuNhuu+3imGOOiZYtW8asWbPi73//e/Tt2zfzj2vbb799RESceeaZse+++0bt2rXjmGOOyZxz3LhxcdBBB1kTnQ1DAnIaNWpUiojMVq9evdS6deu09957pxtvvDHNnz+/zD4XX3xxWvWj9fTTT6dDDjkktW3bNtWrVy+1bds2DRw4ML333ntZ+z366KNp6623TnXq1EkRkUaNGpVSSqlfv36pW7duq42vX79+qV+/fpnHEyZMSBGR7r333jRs2LDUqlWrVFJSkg444IA0c+bMMvv/9re/TT/4wQ9ScXFx6tu3b3rllVfKHHNNsQ0ePDh16NAhq++CBQvSOeeck9q2bZvq1q2btthii3TNNdekFStWZPWLiDR06NAyMXXo0CENHjx4ta93VZ9++mk64YQTUosWLVK9evVSjx49MnF9/3gHHHDAWo+3su+q7/eq2/dfZ0op3XbbbSkiUuPGjdOSJUvKPP/WW2+l/v37p0aNGqUWLVqkU045Jb322mtZY5hS2WsmpZQWL16cTjrppNSkSZPUuHHjdNRRR6W5c+emiEgXX3xxpt+XX36ZGYdGjRqlfffdN73zzjurHcfbbrstbb755ql27dopItKECRNSSmWvo5TKN77Tp09PEZGuueaaMq/9+3GuzvPPP5+GDh2aunfvnpo0aZLq1q2b2rdvn4YMGZKmTZtWpv9jjz2Wdtlll1RSUpJKS0vTTjvtlO69996sPvfff3/q1atXKi4uTs2bN0+DBg1KH374YVafwYMHp4YNG+aM649//GPafvvtU0lJSWrcuHHq0aNH+tWvfpU+/vjjlFJKr776aho4cGBq3759Ki4uTq1atUoHHnhgeuWVV9b4elfq2bNnOumkk3I+P3To0DLXw5q+B55//vm08847p5KSktS2bdv0q1/9Ko0dOzbrPV75ule9jivy/q3uGq3IZ/jpp59OvXr1SvXq1UudO3dOf/rTn9IvfvGLVL9+/Ryj8J1vv/023XbbbenQQw9NHTp0SMXFxalBgwapV69e6ZprrklLly7N6v/NN9+kq6++OnXr1i0VFxenZs2ape233z4NHz48zZs3L9PvnXfeSbvvvnsqKSlJEZEV7/nnn5/at29f5jsLgPWf3H7Nscnt5fZy++rJ7Sszrn/9619p++23T/Xq1Vvr+1TR92jChAlp3333TU2aNEn169dPnTt3TkOGDMmKYdmyZennP/95atmyZSoqKsp6rW+//XaKiDR+/PicMcH6pCilGjRdDQA2cHfddVcMHTo0Zs2aFU2bNi10OAVz6KGHxptvvllmnddCWrp0aXTs2DEuuOCCOOusswodDgAANZzcPrezzz47nn322Zg0aZKZ6GwQrIkOANVo0KBB0b59+7j55psLHUq1WbJkSdbj999/Px5//PHYY489ChNQDqNGjYq6devGT3/600KHAgDAemBjzO3L4/PPP48//elPcfnllyugs8EwEx0AqFJt2rSJIUOGxOabbx4zZ86MkSNHxtKlS2Py5MmxxRZbFDo8AAAAWCM3FgUAqtSAAQPi3nvvjU8++SSKi4ujT58+ceWVVyqgAwAAsF4wEx0AAAAAAHKwJjoAAAAAAOSgiA4AAAAAADms12uir1ixIj7++ONo3Lixu/0CALBeSCnFggULom3btlGr1oYzp0VuDgDA+qa8ufl6XUT/+OOPo127doUOAwAAKmz27Nmx2WabFTqMSiM3BwBgfbW23Hy9LqI3btw4Ir57kaWlpQWOBgAA1m7+/PnRrl27TC67oZCbAwCwvilvbr5eF9FX/ky0tLRUog4AwHplQ1vyRG4OAMD6am25+YazCCMAAAAAAFQyRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAcihoEb1jx45RVFRUZhs6dGghwwIAAAAAgIiIqFPIk7/88suxfPnyzOM33ngj9t577zjyyCMLGBUAAAAAAHynoEX0li1bZj2+6qqronPnztGvX78CRQQAAAAAAP+nxqyJ/s0338Rf/vKXOPHEE6OoqKjQ4QAAAAAAQGFnoq/qkUceia+++iqGDBmSs8/SpUtj6dKlmcfz58+vhsgAAAAAANhY1ZiZ6Lfffnvst99+0bZt25x9RowYEU2aNMls7dq1q8YIAQAAAADY2NSIIvrMmTNj/PjxcfLJJ6+x37Bhw2LevHmZbfbs2dUUIQAAAAAAG6MasZzLqFGjolWrVnHAAQessV9xcXEUFxdXU1QAAAAAAGzsCj4TfcWKFTFq1KgYPHhw1KlTI2r6AAAAAAAQETWgiD5+/PiYNWtWnHjiiYUOBQAAAAAAshR86vc+++wTKaVChwHAapw0+uUK9b99yI5VFAkAAGy8KpqXR8jNASpTwWeiAwAAAABATaWIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAADx0UcfxU9+8pPYZJNNoqSkJHr06BGvvPJKocMCAICCq1PoAAAAgML68ssvo2/fvrHnnnvGE088ES1btoz3338/mjVrVujQAACg4BTRAQBgI3f11VdHu3btYtSoUZm2Tp06FTAiAACoOSznAgAAG7nHHnssdthhhzjyyCOjVatW0atXr7jtttsKHRYAANQIiugAALCR++CDD2LkyJGxxRZbxNixY+P000+PM888M+64446c+yxdujTmz5+ftQEAwIbIci4AALCRW7FiReywww5x5ZVXRkREr1694o033ohbbrklBg8evNp9RowYEcOHD6/OMAEAoCDMRAcAgI1cmzZtYuutt85q22qrrWLWrFk59xk2bFjMmzcvs82ePbuqwwQAgIIwEx0AADZyffv2jXfffTer7b333osOHTrk3Ke4uDiKi4urOjQAACg4M9EBAGAjd84558SLL74YV155ZUydOjXuueee+OMf/xhDhw4tdGgAAFBwiugAALCR23HHHePhhx+Oe++9N7p37x6XXXZZ3HDDDTFo0KBChwYAAAVnORcAACAOPPDAOPDAAwsdBgAA1DhmogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAORS8iP7RRx/FT37yk9hkk02ipKQkevToEa+88kqhwwIAAAAAgKhTyJN/+eWX0bdv39hzzz3jiSeeiJYtW8b7778fzZo1K2RYAAAAAAAQEQUuol999dXRrl27GDVqVKatU6dOBYwIAAAAAAD+T0GXc3nsscdihx12iCOPPDJatWoVvXr1ittuu62QIQEAAAAAQEZBi+gffPBBjBw5MrbYYosYO3ZsnH766XHmmWfGHXfcsdr+S5cujfnz52dtAAAAAABQVQq6nMuKFStihx12iCuvvDIiInr16hVvvPFG3HLLLTF48OAy/UeMGBHDhw+v7jABAAAAANhIFXQmeps2bWLrrbfOattqq61i1qxZq+0/bNiwmDdvXmabPXt2dYQJAAAAAMBGqqAz0fv27RvvvvtuVtt7770XHTp0WG3/4uLiKC4uro7QAAAAAACgsDPRzznnnHjxxRfjyiuvjKlTp8Y999wTf/zjH2Po0KGFDAsAAAAAACKiwEX0HXfcMR5++OG49957o3v37nHZZZfFDTfcEIMGDSpkWAAAAAAAEBEFXs4lIuLAAw+MAw88sNBhAAAAAABAGQWdiQ4AAAAAADWZIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAACwkbvkkkuiqKgoa9tyyy0LHRYAANQIdQodAAAAUHjdunWL8ePHZx7XqeOvCgAAEKGIDgAAxHdF89atWxc6DAAAqHEs5wIAAMT7778fbdu2jc033zwGDRoUs2bNKnRIAABQI5iJDgAAG7nevXvH6NGjo2vXrjFnzpwYPnx47LbbbvHGG29E48aNV7vP0qVLY+nSpZnH8+fPr65wAQCgWimiAwDARm6//fbL/H/Pnj2jd+/e0aFDh3jggQfipJNOWu0+I0aMiOHDh1dXiAAAUDCWcwEAALI0bdo0fvjDH8bUqVNz9hk2bFjMmzcvs82ePbsaIwQAgOqjiA4AAGRZuHBhTJs2Ldq0aZOzT3FxcZSWlmZtAACwIVJEBwCAjdx5550XzzzzTMyYMSP+9a9/xWGHHRa1a9eOgQMHFjo0AAAoOGuiAwDARu7DDz+MgQMHxueffx4tW7aMXXfdNV588cVo2bJloUMDAICCU0QHAICN3H333VfoEAAAoMaynAsAAAAAAOSgiA4AAAAAADkUtIh+ySWXRFFRUda25ZZbFjIkAAAAAADIKPia6N26dYvx48dnHtepU/CQAAAAAAAgImpAEb1OnTrRunXrQocBAAAAAABlFHxN9Pfffz/atm0bm2++eQwaNChmzZqVs+/SpUtj/vz5WRsAAAAAAFSVghbRe/fuHaNHj44nn3wyRo4cGdOnT4/ddtstFixYsNr+I0aMiCZNmmS2du3aVXPEAAAAAABsTApaRN9vv/3iyCOPjJ49e8a+++4bjz/+eHz11VfxwAMPrLb/sGHDYt68eZlt9uzZ1RwxAAAAAAAbk4Kvib6qpk2bxg9/+MOYOnXqap8vLi6O4uLiao4KAAAAAICNVcHXRF/VwoULY9q0adGmTZtChwIAAAAAAIUtop933nnxzDPPxIwZM+Jf//pXHHbYYVG7du0YOHBgIcMCAAAAAICIKPByLh9++GEMHDgwPv/882jZsmXsuuuu8eKLL0bLli0LGRYAAAAAAEREgYvo9913XyFPDwAAAAAAa1Sj1kQHAAAAAICaRBEdAAAAAAByUEQHAAAAAIAcFNEBAAAAACAHRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQAAAAAgB0V0AAAAAADIQREdAAAAAAByUEQHAAAAAIAcFNEBAAAAACAHRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQAAAAAgB0V0AAAAAADIQREdAAAAAAByUEQHAAAAAIAcFNEBAAAAACAHRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQCALFdddVUUFRXF2WefXehQAACg4BTRAQCAjJdffjluvfXW6NmzZ6FDAQCAGkERHQAAiIiIhQsXxqBBg+K2226LZs2aFTocAACoERTRAQCAiIgYOnRoHHDAAdG/f/+19l26dGnMnz8/awMAgA1RnUIHAAAAFN59990Xr776arz88svl6j9ixIgYPnx4FUcFAACFZyY6AABs5GbPnh1nnXVW3H333VG/fv1y7TNs2LCYN29eZps9e3YVRwkAAIVhJjoAAGzkJk2aFHPnzo3tttsu07Z8+fJ49tln4/e//30sXbo0ateunbVPcXFxFBcXV3eoAABQ7RTRAQBgI7fXXnvF66+/ntV2wgknxJZbbhnnn39+mQI6AABsTBTRAQBgI9e4cePo3r17VlvDhg1jk002KdMOAAAbG2uiAwAAAABADjWmiH7VVVdFUVFRnH322YUOBQAANnoTJ06MG264odBhAABAweVVRP/ggw8qNYiXX345br311ujZs2elHhcAADZ0lZ2bAwAA2fIqonfp0iX23HPP+Mtf/hJff/31OgWwcOHCGDRoUNx2223RrFmzdToWAABsbCozNwcAAMrKq4j+6quvRs+ePePcc8+N1q1bx2mnnRb//ve/8wpg6NChccABB0T//v3X2nfp0qUxf/78rA0AADZmlZmbAwAAZeVVRN92223jxhtvjI8//jj+/Oc/x5w5c2LXXXeN7t27x3XXXRf//e9/y3Wc++67L1599dUYMWJEufqPGDEimjRpktnatWuXT/gAALDBqKzcHAAAWL11urFonTp14vDDD48xY8bE1VdfHVOnTo3zzjsv2rVrF8cff3zMmTMn576zZ8+Os846K+6+++6oX79+uc43bNiwmDdvXmabPXv2uoQPAAAbjHXJzQEAgNzWqYj+yiuvxM9+9rNo06ZNXHfddXHeeefFtGnTYty4cfHxxx/HIYccknPfSZMmxdy5c2O77baLOnXqRJ06deKZZ56J3/3ud1GnTp1Yvnx5mX2Ki4ujtLQ0awMAANYtNwcAAHKrk89O1113XYwaNSrefffd2H///ePOO++M/fffP2rV+q4m36lTpxg9enR07Ngx5zH22muveP3117PaTjjhhNhyyy3j/PPPj9q1a+cTGgAAbFQqIzcHAAByy6uIPnLkyDjxxBNjyJAh0aZNm9X2adWqVdx+++05j9G4cePo3r17VlvDhg1jk002KdMOAACsXmXk5gAAQG55FdHHjRsX7du3z8xuWSmlFLNnz4727dtHvXr1YvDgwZUSJAAAsHpycwAAqFp5FdE7d+4cc+bMiVatWmW1f/HFF9GpU6fVrmdeHhMnTsxrPwAA2FhVVW4OAAB8J68bi6aUVtu+cOHCqF+//joFBAAAlJ/cHAAAqlaFZqKfe+65ERFRVFQUF110UTRo0CDz3PLly+Oll16KbbfdtlIDBAAAypKbAwBA9ahQEX3y5MkR8d1sl9dffz3q1auXea5evXqxzTbbxHnnnVe5EQIAAGXIzQEAoHpUqIg+YcKEiIg44YQT4sYbb4zS0tIqCQoAAFgzuTkAAFSPvG4sOmrUqMqOAwAAyIPcHAAAqla5i+iHH354jB49OkpLS+Pwww9fY9+HHnponQMDAABWT24OAADVp9xF9CZNmkRRUVHm/wEAgMKQmwMAQPUpdxF91Z+J+skoAAAUjtwcAACqT618dlqyZEksXrw483jmzJlxww03xFNPPVVpgQEAAGsnNwcAgKqVVxH9kEMOiTvvvDMiIr766qvYaaed4re//W0ccsghMXLkyEoNEAAAyE1uDgAAVSuvIvqrr74au+22W0REPPjgg9G6deuYOXNm3HnnnfG73/2uUgMEAAByk5sDAEDVyquIvnjx4mjcuHFERDz11FNx+OGHR61atWLnnXeOmTNnVmqAAABAbnJzAACoWnkV0bt06RKPPPJIzJ49O8aOHRv77LNPRETMnTs3SktLKzVAAAAgN7k5AABUrbyK6BdddFGcd9550bFjx+jdu3f06dMnIr6b+dKrV69KDRAAAMhNbg4AAFWrTj47HXHEEbHrrrvGnDlzYptttsm077XXXnHYYYdVWnAAAMCayc0BAKBq5VVEj4ho3bp1tG7dOqttp512WueAAACAipGbAwBA1cmriL5o0aK46qqr4umnn465c+fGihUrsp7/4IMPKiU4AABgzeTmAABQtfIqop988snxzDPPxHHHHRdt2rSJoqKiyo4LAAAoB7k5AABUrbyK6E888UT8/e9/j759+1Z2PAAAQAXIzQEAoGrVymenZs2aRfPmzSs7FgAAoILk5gAAULXyKqJfdtllcdFFF8XixYsrOx4AAKAC5OYAAFC18lrO5be//W1MmzYtNt100+jYsWPUrVs36/lXX321UoIDAADWTG4OAABVK68i+qGHHlrJYQAAAPmQmwMAQNXKq4h+8cUXV3YcAABAHuTmAABQtfJaEz0i4quvvoo//elPMWzYsPjiiy8i4rufin700UeVFhwAALB2cnMAAKg6ec1E/89//hP9+/ePJk2axIwZM+KUU06J5s2bx0MPPRSzZs2KO++8s7LjBAAAVkNuDgAAVSuvmejnnntuDBkyJN5///2oX79+pn3//fePZ599ttKCAwAA1kxuDgAAVSuvIvrLL78cp512Wpn2H/zgB/HJJ5+sc1AAAED5yM0BAKBq5VVELy4ujvnz55dpf++996Jly5brHBQAAFA+cnMAAKhaeRXRDz744Lj00kvj22+/jYiIoqKimDVrVpx//vnx4x//uFIDBAAAcpObAwBA1cqriP7b3/42Fi5cGC1btowlS5ZEv379okuXLtG4ceO44oorKjtGAAAgB7k5AABUrTr57NSkSZMYN25cPP/88/Haa6/FwoULY7vttov+/ftXdnwAAMAayM0BAKBqVbiIvmLFihg9enQ89NBDMWPGjCgqKopOnTpF69atI6UURUVFVREnAADwPXJzAACoehVaziWlFAcffHCcfPLJ8dFHH0WPHj2iW7duMXPmzBgyZEgcdthhVRUnAACwCrk5AABUjwrNRB89enQ8++yz8fTTT8eee+6Z9dw//vGPOPTQQ+POO++M448/vlKDBAAAssnNAQCgelRoJvq9994bF154YZkkPSLiRz/6UVxwwQVx9913V1pwAADA6snNAQCgelSoiP6f//wnBgwYkPP5/fbbL1577bV1DgoAAFgzuTkAAFSPChXRv/jii9h0001zPr/pppvGl19+uc5BAQAAa1aZufnIkSOjZ8+eUVpaGqWlpdGnT5944oknKitUAABYr1WoiL58+fKoUyf3Muq1a9eOZcuWrXNQAADAmlVmbr7ZZpvFVVddFZMmTYpXXnklfvSjH8UhhxwSb775ZmWFCwAA660K3Vg0pRRDhgyJ4uLi1T6/dOnSSgkKAABYs8rMzQ866KCsx1dccUWMHDkyXnzxxejWrds6xQkAAOu7ChXRBw8evNY+xx9/fN7BAAAA5VNVufny5ctjzJgxsWjRoujTp0/OfkuXLs0q1M+fP7/C5wIAgPVBhYroo0aNqqo4AACACqjs3Pz111+PPn36xNdffx2NGjWKhx9+OLbeeuuc/UeMGBHDhw+v1BgAAKAmqtCa6AAAwIapa9euMWXKlHjppZfi9NNPj8GDB8dbb72Vs/+wYcNi3rx5mW327NnVGC0AAFSfCs1EBwAANkz16tWLLl26RETE9ttvHy+//HLceOONceutt662f3Fxcc712AFYs5NGv1zoEACogILORB85cmT07NkzSktLo7S0NPr06RNPPPFEIUMCAAAiYsWKFRW6OSkAAGyoCjoTfbPNNourrroqtthii0gpxR133BGHHHJITJ48Obp161bI0AAAYKMxbNiw2G+//aJ9+/axYMGCuOeee2LixIkxduzYQocGAAAFV9Ai+kEHHZT1+IorroiRI0fGiy++qIgOAADVZO7cuXH88cfHnDlzokmTJtGzZ88YO3Zs7L333oUODQAACq7GrIm+fPnyGDNmTCxatCj69OlT6HAAAGCjcfvttxc6BAAAqLEKXkR//fXXo0+fPvH1119Ho0aN4uGHH46tt956tX2XLl2atS7j/PnzqytMAAAAAAA2QgW9sWhERNeuXWPKlCnx0ksvxemnnx6DBw+Ot956a7V9R4wYEU2aNMls7dq1q+ZoAQAAAADYmBS8iF6vXr3o0qVLbL/99jFixIjYZptt4sYbb1xt32HDhsW8efMy2+zZs6s5WgAAAAAANiYFX87l+1asWJG1ZMuqiouLo7i4uJojAgAAAABgY1XQIvqwYcNiv/32i/bt28eCBQvinnvuiYkTJ8bYsWMLGRYAAAAAAEREgYvoc+fOjeOPPz7mzJkTTZo0iZ49e8bYsWNj7733LmRYAAAAAAAQEQUuot9+++2FPD3ARuWk0S8XOgQAAACA9U7BbywKAAAAAAA1lSI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAALCRGzFiROy4447RuHHjaNWqVRx66KHx7rvvFjosAACoERTRAQBgI/fMM8/E0KFD48UXX4xx48bFt99+G/vss08sWrSo0KEBAEDB1Sl0AAAAQGE9+eSTWY9Hjx4drVq1ikmTJsXuu+9eoKgAAKBmUEQHAACyzJs3LyIimjdvnrPP0qVLY+nSpZnH8+fPr/K4AACgECznAgAAZKxYsSLOPvvs6Nu3b3Tv3j1nvxEjRkSTJk0yW7t27aoxSgAAqD4FLaK7gREAANQsQ4cOjTfeeCPuu+++NfYbNmxYzJs3L7PNnj27miIEAIDqVdAiuhsYAQBAzXHGGWfE3/72t5gwYUJsttlma+xbXFwcpaWlWRsAAGyICromuhsYAQBA4aWU4uc//3k8/PDDMXHixOjUqVOhQwIAgBqjRt1YdG03MHLzIgAAqHxDhw6Ne+65Jx599NFo3LhxfPLJJxER0aRJkygpKSlwdAAAUFg15sai5bmBkZsXAQBA5Rs5cmTMmzcv9thjj2jTpk1mu//++wsdGgAAFFyNmYm+8gZG//znP3P2GTZsWJx77rmZx/Pnz1dIBwCAdZRSKnQIAABQY9WIIvrKGxg9++yza7yBUXFxcRQXF1djZAAAAAAAbMwKWkR3AyMAAAAAAGqyghbR3cAIAAAAAICarKA3FnUDIwAAAAAAarKCL+cCAAAAAAA1VUFnogMAAAAAQE2miA4AAAAAADkoogMAAAAAQA6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADnUKHQAAG46TRr9c4X1uH7JjFUQCAAAAUDnMRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHOoUOgAAAAAAKtdJo1+uUP/bh+xYRZEArP/MRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQAAAAAgB0V0AAAAAADIQREdAAAAAAByUEQHAAAAAIAcFNEBAAAAACAHRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEBwAAAACAHBTRAQAAAAAgB0V0AAAAAADIQREdAAAAAAByUEQHAAAAAIAcFNEBAAAAACCHOoUOAAAAAIDCOmn0yxXe5/YhO1ZBJAA1j5noAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJBDnUIHAEB+Thr9cqFDAGAD8uyzz8Y111wTkyZNijlz5sTDDz8chx56aKHDAqjx5OUAGz4z0QEAgFi0aFFss802cfPNNxc6FAAAqFHMRAcAAGK//faL/fbbr9BhAABAjVPQmejPPvtsHHTQQdG2bdsoKiqKRx55pJDhAAAAAABAloLORF/5k9ETTzwxDj/88EKGAkCBVHQNyduH7FhFkQBQEUuXLo2lS5dmHs+fP7+A0QAAQNUpaBHdT0YBAGD9NGLEiBg+fHihwwAAgCq3Xt1YdOnSpTF//vysDQAAqH7Dhg2LefPmZbbZs2cXOiQAAKgS61URfcSIEdGkSZPM1q5du0KHBAAAG6Xi4uIoLS3N2gAAYEO0XhXRzXYBAICqsXDhwpgyZUpMmTIlIiKmT58eU6ZMiVmzZhU2MAAAKLCCroleUcXFxVFcXFzoMAAAYIPzyiuvxJ577pl5fO6550ZExODBg2P06NEFigoAAApvvSqiAwAAVWOPPfaIlFKhwwBgPXLS6Jcr1P/2ITtWUSQAVaugRfSFCxfG1KlTM49X/mS0efPm0b59+wJGBgAAAABARVX0H9giav4/shW0iO4nowAAAAAA1GQFLaL7ySgAAAAAADVZrUIHAAAAAAAANZUiOgAAAAAA5FDQ5VwAAACADUNFbyRX028iBwArmYkOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDNdEBANggWIsXAACoCmaiAwAAAABADmaiA9QAFZ09uTHLZ6yqY7ZpTY0LAAAAWDeK6OtAwQQAAAA2LCa41CxqL0BNoIgOAN/jL04AADWT+1+s3+TZwPpKER1Yr5mVAAAAwKr8YwtQ2RTRAQAAgGpnVjIA6wtFdGCjY1YCAABsHBTqAagMiugAAMB6zxJvAOTLnyHA2iiiA7DBMwMJAKBi5E8A8H8U0QGqgL90AAAAAGwYahU6AAAAAAAAqKnMRAdYC7PKqSpucgsAAAA1n5noAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5WBMdqFGsPw4AAABATWImOgAAAAAA5KCIDgAAAAAAOVjOBQDWE/ksd3T7kB2rIBIAYH1j2UQAyJ+Z6AAAAAAAkIMiOgAAAAAA5GA5F6DK+MkoAAAAAOs7RXQAAAAAqICKThpzryJYvymiA+ViVjkAAAAAGyNrogMAAAAAQA5mogPABszPTAFgw+NXorD+yedzKzeHmkMRHQAAAApEQRwAaj5FdAAAAACoYfyqFGoORXQAIMPPTAEAACCbIjpspPxsFAAAAADWrlahAwAAAAAAgJpKER0AAAAAAHKwnAtsACzNAgAAAABVQxEdAFgnFf2HPDciBQCAypfPBDu5OZSP5VwAAAAAACAHM9EBgGplhgwAGzJLLQLrE78qhfIxEx0AAAAAAHKoETPRb7755rjmmmvik08+iW222SZuuumm2GmnnQodFhSM2SsAQCHIywGANfGrUjZWBS+i33///XHuuefGLbfcEr17944bbrgh9t1333j33XejVatWhQ4PAKgB/MwUqp68HMoyuQUAiKgBRfTrrrsuTjnllDjhhBMiIuKWW26Jv//97/HnP/85LrjgggJHB+tO4g0ArA/k5WwM5OYA1c+EGDYEBS2if/PNNzFp0qQYNmxYpq1WrVrRv3//eOGFFwoYGeQm8Qao+fzMFCpGXg4A1BRyeWqighbRP/vss1i+fHlsuummWe2bbrppvPPOO2X6L126NJYuXZp5PG/evIiImD9/ftUGmsM3SxZWeJ9CxVoTDL17UqFDAICcjhs5odAhVIqbB21f6BAKpqK5WaHyspXnTSkV5PyrU9G8PEJuXpPIswHY2FU0l9+Yc+bqsD7lZeXNzQu+nEtFjBgxIoYPH16mvV27dgWIJj9/+VmhIwAANmRyjfIr9FgtWLAgmjRpUtgg1oHcHABYX8kBap5Cvydry80LWkRv0aJF1K5dOz799NOs9k8//TRat25dpv+wYcPi3HPPzTxesWJFfPHFF7HJJptEUVFRlce7qvnz50e7du1i9uzZUVpaWq3nXt8Zu/wYt/wYt/wZu/wYt/wYt/wZu/wUctxSSrFgwYJo27ZttZ53TSqal0fIzTcExi1/xi4/xi0/xi1/xi4/xi0/xi1/60NuXtAier169WL77bePp59+Og499NCI+C75fvrpp+OMM84o07+4uDiKi4uz2po2bVoNkeZWWlrqg5EnY5cf45Yf45Y/Y5cf45Yf45Y/Y5efQo1bTZuBXtG8PEJuviExbvkzdvkxbvkxbvkzdvkxbvkxbvmrybl5wZdzOffcc2Pw4MGxww47xE477RQ33HBDLFq0KE444YRChwYAABsNeTkAAKxewYvoRx99dPz3v/+Niy66KD755JPYdttt48knnyxzUyMAAKDqyMsBAGD1Cl5Ej4g444wzcv5MtKYqLi6Oiy++uMxPWFk7Y5cf45Yf45Y/Y5cf45Yf45Y/Y5cf47Z662NeHuH9zJdxy5+xy49xy49xy5+xy49xy49xy9/6MHZFKaVU6CAAAAAAAKAmqlXoAAAAAAAAoKZSRAcAAAAAgBwU0QEAAAAAIAdF9DW44oorYpdddokGDRpE06ZNy7VPSikuuuiiaNOmTZSUlET//v3j/fffz+rzxRdfxKBBg6K0tDSaNm0aJ510UixcuLAKXkFhVPT1zZgxI4qKila7jRkzJtNvdc/fd9991fGSqk0+18Yee+xRZlx++tOfZvWZNWtWHHDAAdGgQYNo1apV/PKXv4xly5ZV5UupVhUdty+++CJ+/vOfR9euXaOkpCTat28fZ555ZsybNy+r34Z2zd18883RsWPHqF+/fvTu3Tv+/e9/r7H/mDFjYsstt4z69etHjx494vHHH896vjzfdxuKiozdbbfdFrvttls0a9YsmjVrFv379y/Tf8iQIWWurQEDBlT1y6h2FRm30aNHlxmT+vXrZ/XZWK65iozb6v4MKCoqigMOOCDTZ2O43p599tk46KCDom3btlFUVBSPPPLIWveZOHFibLfddlFcXBxdunSJ0aNHl+lT0e9Nqo68PH9y8/zIy/MjLy8/uXl+5OX5k5vnR25ecRtsbp7I6aKLLkrXXXddOvfcc1OTJk3Ktc9VV12VmjRpkh555JH02muvpYMPPjh16tQpLVmyJNNnwIABaZtttkkvvvhieu6551KXLl3SwIEDq+hVVL+Kvr5ly5alOXPmZG3Dhw9PjRo1SgsWLMj0i4g0atSorH6rjuuGIJ9ro1+/fumUU07JGpd58+Zlnl+2bFnq3r176t+/f5o8eXJ6/PHHU4sWLdKwYcOq+uVUm4qO2+uvv54OP/zw9Nhjj6WpU6emp59+Om2xxRbpxz/+cVa/Demau++++1K9evXSn//85/Tmm2+mU045JTVt2jR9+umnq+3//PPPp9q1a6f//d//TW+99Vb6n//5n1S3bt30+uuvZ/qU5/tuQ1DRsTv22GPTzTffnCZPnpzefvvtNGTIkNSkSZP04YcfZvoMHjw4DRgwIOva+uKLL6rrJVWLio7bqFGjUmlpadaYfPLJJ1l9NoZrrqLj9vnnn2eN2RtvvJFq166dRo0alemzMVxvjz/+ePr1r3+dHnrooRQR6eGHH15j/w8++CA1aNAgnXvuuemtt95KN910U6pdu3Z68sknM30q+l5QteTl+ZOb50denh95efnIzfMjL8+f3Dw/cvP8bKi5uSJ6OYwaNapcyfqKFStS69at0zXXXJNp++qrr1JxcXG69957U0opvfXWWyki0ssvv5zp88QTT6SioqL00UcfVXrs1a2yXt+2226bTjzxxKy28nzw1mf5jl2/fv3SWWedlfP5xx9/PNWqVSvrD7yRI0em0tLStHTp0kqJvZAq65p74IEHUr169dK3336baduQrrmddtopDR06NPN4+fLlqW3btmnEiBGr7X/UUUelAw44IKutd+/e6bTTTksple/7bkNR0bH7vmXLlqXGjRunO+64I9M2ePDgdMghh1R2qDVKRcdtbX/WbizX3Lpeb9dff31q3LhxWrhwYaZtY7jeVlWe7+5f/epXqVu3blltRx99dNp3330zj9f1vaBqyMsrRm6eH3l5fuTl5Sc3z4+8PH9y8/zIzdfdhpSbW86lEk2fPj0++eST6N+/f6atSZMm0bt373jhhRciIuKFF16Ipk2bxg477JDp079//6hVq1a89NJL1R5zZauM1zdp0qSYMmVKnHTSSWWeGzp0aLRo0SJ22mmn+POf/xwppUqLvdDWZezuvvvuaNGiRXTv3j2GDRsWixcvzjpujx49YtNNN8207bvvvjF//vx48803K/+FVLPK+kzNmzcvSktLo06dOlntG8I1980338SkSZOyvptq1aoV/fv3z3w3fd8LL7yQ1T/iu+tmZf/yfN9tCPIZu+9bvHhxfPvtt9G8efOs9okTJ0arVq2ia9eucfrpp8fnn39eqbEXUr7jtnDhwujQoUO0a9cuDjnkkKzvqI3hmquM6+3222+PY445Jho2bJjVviFfb/lY23dcZbwXFJa8/Dty8/zIy/MjLy8fuXl+5OX5k5vnR25efdaX3LzO2rtQXp988klERFZStPLxyuc++eSTaNWqVdbzderUiebNm2f6rM8q4/XdfvvtsdVWW8Uuu+yS1X7ppZfGj370o2jQoEE89dRT8bOf/SwWLlwYZ555ZqXFX0j5jt2xxx4bHTp0iLZt28Z//vOfOP/88+Pdd9+Nhx56KHPc1V2TK59b31XGNffZZ5/FZZddFqeeempW+4ZyzX322WexfPny1V4H77zzzmr3yXXdrPpdtrItV58NQT5j933nn39+tG3bNusP/AEDBsThhx8enTp1imnTpsWFF14Y++23X7zwwgtRu3btSn0NhZDPuHXt2jX+/Oc/R8+ePWPevHlx7bXXxi677BJvvvlmbLbZZhvFNbeu19u///3veOONN+L222/Pat/Qr7d85PqOmz9/fixZsiS+/PLLdf7sU1jy8u/IzfMjL8+PvLx85Ob5kZfnT26eH7l59VlfcvONroh+wQUXxNVXX73GPm+//XZsueWW1RTR+qG847aulixZEvfcc0/85je/KfPcqm29evWKRYsWxTXXXFPjE6eqHrtVE8wePXpEmzZtYq+99opp06ZF586d8z5uoVXXNTd//vw44IADYuutt45LLrkk67n19Zqj5rjqqqvivvvui4kTJ2bdiOeYY47J/H+PHj2iZ8+e0blz55g4cWLstddehQi14Pr06RN9+vTJPN5ll11iq622iltvvTUuu+yyAka2/rj99tujR48esdNOO2W1u96oqeTl+ZOb50denh95ORsCeXnFyM3Xndx8w7PRFdF/8YtfxJAhQ9bYZ/PNN8/r2K1bt46IiE8//TTatGmTaf/0009j2223zfSZO3du1n7Lli2LL774IrN/TVTecVvX1/fggw/G4sWL4/jjj19r3969e8dll10WS5cujeLi4rX2L5TqGruVevfuHRERU6dOjc6dO0fr1q3L3LH4008/jYjY6K+5BQsWxIABA6Jx48bx8MMPR926ddfYf3255r6vRYsWUbt27cz7vtKnn36ac4xat269xv7l+b7bEOQzditde+21cdVVV8X48eOjZ8+ea+y7+eabR4sWLWLq1KkbROK0LuO2Ut26daNXr14xderUiNg4rrl1GbdFixbFfffdF5deeulaz7OhXW/5yPUdV1paGiUlJVG7du11voZZO3l5/uTm+ZGX50deXrnk5vmRl+dPbp4fuXn1WW9y82pbfX09VtEbGF177bWZtnnz5q32BkavvPJKps/YsWM3mBsYrevr69evX5k7sedy+eWXp2bNmuUda01TWdfGP//5zxQR6bXXXksp/d8NjFa9Y/Gtt96aSktL09dff115L6BA8h23efPmpZ133jn169cvLVq0qFznWp+vuZ122imdccYZmcfLly9PP/jBD9Z486IDDzwwq61Pnz5lbl60pu+7DUVFxy6llK6++upUWlqaXnjhhXKdY/bs2amoqCg9+uij6xxvTZHPuK1q2bJlqWvXrumcc85JKW0811y+4zZq1KhUXFycPvvss7WeY0O83lYV5bx5Uffu3bPaBg4cWObmRetyDVM15OUVIzfPj7w8P/Ly8pOb50denj+5eX7k5utuQ8rNFdHXYObMmWny5Mlp+PDhqVGjRmny5Mlp8uTJacGCBZk+Xbt2TQ899FDm8VVXXZWaNm2aHn300fSf//wnHXLIIalTp05pyZIlmT4DBgxIvXr1Si+99FL65z//mbbYYos0cODAan1tVWltr+/DDz9MXbt2TS+99FLWfu+//34qKipKTzzxRJljPvbYY+m2225Lr7/+enr//ffTH/7wh9SgQYN00UUXVfnrqU4VHbupU6emSy+9NL3yyitp+vTp6dFHH02bb7552n333TP7LFu2LHXv3j3ts88+acqUKenJJ59MLVu2TMOGDav211dVKjpu8+bNS7179049evRIU6dOTXPmzMlsy5YtSylteNfcfffdl4qLi9Po0aPTW2+9lU499dTUtGnT9Mknn6SUUjruuOPSBRdckOn//PPPpzp16qRrr702vf322+niiy9OdevWTa+//nqmT3m+7zYEFR27q666KtWrVy89+OCDWdfWyj87FixYkM4777z0wgsvpOnTp6fx48en7bbbLm2xxRYbxF+gV6rouA0fPjyNHTs2TZs2LU2aNCkdc8wxqX79+unNN9/M9NkYrrmKjttKu+66azr66KPLtG8s19uCBQsyeVpEpOuuuy5Nnjw5zZw5M6WU0gUXXJCOO+64TP8PPvggNWjQIP3yl79Mb7/9drr55ptT7dq105NPPpnps7b3guolL8+f3Dw/8vL8yMvLR26eH3l5/uTm+ZGb52dDzc0V0ddg8ODBKSLKbBMmTMj0iYg0atSozOMVK1ak3/zmN2nTTTdNxcXFaa+99krvvvtu1nE///zzNHDgwNSoUaNUWlqaTjjhhKy/AKzv1vb6pk+fXmYcU0pp2LBhqV27dmn58uVljvnEE0+kbbfdNjVq1Cg1bNgwbbPNNumWW25Zbd/1WUXHbtasWWn33XdPzZs3T8XFxalLly7pl7/8ZZo3b17WcWfMmJH222+/VFJSklq0aJF+8YtfpG+//bY6X1qVqui4TZgwYbWf7YhI06dPTyltmNfcTTfdlNq3b5/q1auXdtppp/Tiiy9mnuvXr18aPHhwVv8HHngg/fCHP0z16tVL3bp1S3//+9+zni/P992GoiJj16FDh9VeWxdffHFKKaXFixenffbZJ7Vs2TLVrVs3dejQIZ1yyikbZGGuIuN29tlnZ/puuummaf/990+vvvpq1vE2lmuuop/Vd955J0VEeuqpp8oca2O53nJ9r68cq8GDB6d+/fqV2WfbbbdN9erVS5tvvnlWPrfSmt4Lqpe8PH9y8/zIy/MjLy8/uXl+5OX5k5vnR25ecRtqbl6UUkrruiQMAAAAAABsiGoVOgAAAAAAAKipFNEBAAAAACAHRXQAAAAAAMhBER0AAAAAAHJQRAcAAAAAgBwU0QEAAAAAIAdFdAAAAAAAyEERHQAAAAAAclBEB6ihZsyYEUVFRTFlypQqP9fo0aOjadOmVX4eAABYH8nNATZuiugAeRgyZEgUFRWV2QYMGFDo0NaqY8eOccMNN2S1HX300fHee+9V+bmnT58exx57bLRt2zbq168fm222WRxyyCHxzjvvVPm5AQDYMMnN8yM3Byi/OoUOAGB9NWDAgBg1alRWW3FxcYGiWTclJSVRUlJSpef49ttvY++9946uXbvGQw89FG3atIkPP/wwnnjiifjqq6+q9Lx169atsuMDAFB4cvOKkZsDVIyZ6AB5Ki4ujtatW2dtzZo1i4iIY489No4++uis/t9++220aNEi7rzzzoiIePLJJ2PXXXeNpk2bxiabbBIHHnhgTJs2Lef5VvezzkceeSSKiooyj6dNmxaHHHJIbLrpptGoUaPYcccdY/z48Znn99hjj5g5c2acc845mRk6uY49cuTI6Ny5c9SrVy+6du0ad911V9bzRUVF8ac//SkOO+ywaNCgQWyxxRbx2GOP5Yz/zTffjGnTpsUf/vCH2HnnnaNDhw7Rt2/fuPzyy2PnnXfO9Pvwww9j4MCB0bx582jYsGHssMMO8dJLL1UorpEjR8bBBx8cDRs2jCuuuCIiIh599NHYbrvton79+rH55pvH8OHDY9myZTnjBQBg/SE3l5sDVCVFdIAqMGjQoPjrX/8aCxcuzLSNHTs2Fi9eHIcddlhERCxatCjOPffceOWVV+Lpp5+OWrVqxWGHHRYrVqzI+7wLFy6M/fffP55++umYPHlyDBgwIA466KCYNWtWREQ89NBDsdlmm8Wll14ac+bMiTlz5qz2OA8//HCcddZZ8Ytf/CLeeOONOO200+KEE06ICRMmZPUbPnx4HHXUUfGf//wn9t9//xg0aFB88cUXqz1my5Yto1atWvHggw/G8uXLc8bfr1+/+Oijj+Kxxx6L1157LX71q19lxqS8cV1yySVx2GGHxeuvvx4nnnhiPPfcc3H88cfHWWedFW+99VbceuutMXr06EwSDwDAhktuXpbcHKCCEgAVNnjw4FS7du3UsGHDrO2KK65IKaX07bffphYtWqQ777wzs8/AgQPT0UcfnfOY//3vf1NEpNdffz2llNL06dNTRKTJkyenlFIaNWpUatKkSdY+Dz/8cFrbV3m3bt3STTfdlHncoUOHdP3112f1+f6xd9lll3TKKadk9TnyyCPT/vvvn3kcEel//ud/Mo8XLlyYIiI98cQTOWP5/e9/nxo0aJAaN26c9txzz3TppZemadOmZZ6/9dZbU+PGjdPnn3++2v3LG9fZZ5+d1WevvfZKV155ZVbbXXfdldq0aZMzVgAA1g9yc7k5QFUzEx0gT3vuuWdMmTIla/vpT38aERF16tSJo446Ku6+++6I+G5my6OPPhqDBg3K7P/+++/HwIEDY/PNN4/S0tLo2LFjRERmZko+Fi5cGOedd15stdVW0bRp02jUqFG8/fbbFT7m22+/HX379s1q69u3b7z99ttZbT179sz8f8OGDaO0tDTmzp2b87hDhw6NTz75JO6+++7o06dPjBkzJrp16xbjxo2LiIgpU6ZEr169onnz5usU1w477JD1+LXXXotLL700GjVqlNlOOeWUmDNnTixevDhnvAAArB/k5nJzgKrkxqIAeWrYsGF06dIl5/ODBg2Kfv36xdy5c2PcuHFRUlISAwYMyDx/0EEHRYcOHeK2226Ltm3bxooVK6J79+7xzTffrPZ4tWrVipRSVtu3336b9fi8886LcePGxbXXXhtdunSJkpKSOOKII3Iec119/6ZARUVFa/3Ja+PGjeOggw6Kgw46KC6//PLYd9994/LLL4+999670m6g1LBhw6zHCxcujOHDh8fhhx9epm/9+vUr5ZwAABSO3FxuDlCVzEQHqCK77LJLtGvXLu6///64++6748gjj8wktp9//nm8++678T//8z+x1157xVZbbRVffvnlGo/XsmXLWLBgQSxatCjTNmXKlKw+zz//fAwZMiQOO+yw6NGjR7Ru3TpmzJiR1adevXo51z1caauttornn3++zLG33nrrtbzqiikqKoott9wy85p69uwZU6ZMybl2Y75xbbfddvHuu+9Gly5dymy1avmjEABgQyc3Xzu5OUBuZqID5Gnp0qXxySefZLXVqVMnWrRokXl87LHHxi233BLvvfde1g12mjVrFptsskn88Y9/jDZt2sSsWbPiggsuWOP5evfuHQ0aNIgLL7wwzjzzzHjppZdi9OjRWX222GKLeOihh+Kggw6KoqKi+M1vflNm9knHjh3j2WefjWOOOSaKi4uz4l3pl7/8ZRx11FHRq1ev6N+/f/z1r3+Nhx56KMaPH1/e4SljypQpcfHFF8dxxx0XW2+9ddSrVy+eeeaZ+POf/xznn39+REQMHDgwrrzyyjj00ENjxIgR0aZNm5g8eXK0bds2+vTpk3dcF110URx44IHRvn37OOKII6JWrVrx2muvxRtvvBGXX3553q8JAICaQW5eMXJzgAoq9KLsAOujwYMHp4gos3Xt2jWr31tvvZUiInXo0CGtWLEi67lx48alrbbaKhUXF6eePXumiRMnpohIDz/8cEqp7M2LUvruZkVdunRJJSUl6cADD0x//OMfs25eNH369LTnnnumkpKS1K5du/T73/8+9evXL5111lmZPi+88ELq2bNnKi4uzuy7uhsj/eEPf0ibb755qlu3bvrhD3+YdSOmlFJWrCs1adIkjRo1arVj9t///jedeeaZqXv37qlRo0apcePGqUePHunaa69Ny5cvz/SbMWNG+vGPf5xKS0tTgwYN0g477JBeeumldYorpZSefPLJtMsuu6SSkpJUWlqadtppp/THP/5xtbECALD+kJvLzQGqWlFK31vECwAAAAAAiAhrogMAAAAAQE6K6AAAAAAAkIMiOgAAAAAA5KCIDgAAAAAAOSiiAwAAAABADoroAAAAAACQgyI6AAAAAADkoIgOAAAAAAA5KKIDAAAAAEAOiugAAAAAAJCDIjoAAAAAAOSgiA4AAAAAADn8f4mRZ/qOj/5kAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set Statistics:\n",
      "Mean: 0.011\n",
      "Std: 0.305\n",
      "Min: -1.000\n",
      "Max: 1.000\n",
      "\n",
      "Test Set Statistics:\n",
      "Mean: 0.018\n",
      "Std: 0.306\n",
      "Min: -1.000\n",
      "Max: 1.000\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Training data distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_Y, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Distribution of Evaluation Scores (Training Set)')\n",
    "plt.xlabel('Evaluation Score')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "# Test data distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_Y, bins=50, density=True, alpha=0.7)\n",
    "plt.title('Distribution of Evaluation Scores (Test Set)')\n",
    "plt.xlabel('Evaluation Score')\n",
    "plt.ylabel('Density')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print some basic statistics\n",
    "print(\"\\nTraining Set Statistics:\")\n",
    "print(f\"Mean: {np.mean(train_Y):.3f}\")\n",
    "print(f\"Std: {np.std(train_Y):.3f}\")\n",
    "print(f\"Min: {np.min(train_Y):.3f}\")\n",
    "print(f\"Max: {np.max(train_Y):.3f}\")\n",
    "\n",
    "print(\"\\nTest Set Statistics:\")\n",
    "print(f\"Mean: {np.mean(test_Y):.3f}\")\n",
    "print(f\"Std: {np.std(test_Y):.3f}\")\n",
    "print(f\"Min: {np.min(test_Y):.3f}\")\n",
    "print(f\"Max: {np.max(test_Y):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "885b6edf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:04:43.114088Z",
     "start_time": "2024-12-08T00:04:43.106365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367006, 12, 8, 8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7b0642d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T00:04:45.473883Z",
     "start_time": "2024-12-08T00:04:45.461308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367006,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58464af1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:47:34.623767Z",
     "start_time": "2024-12-07T22:47:34.620596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.17)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7ca2e34fb41961",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:47:38.601938Z",
     "start_time": "2024-12-07T22:47:38.596661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 1]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 1, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 1, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]], dtype=int8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a23796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ad65bb250ea4f88",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-08T00:04:49.852854Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youcefboumar/PycharmProjects/ChessAI/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m19:57:13 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [1/100], Train Loss: 0.0806, Test Loss: 1.1240, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:57:37 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [2/100], Train Loss: 0.0440, Test Loss: 0.1534, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:58:02 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [3/100], Train Loss: 0.0390, Test Loss: 0.0796, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:58:27 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [4/100], Train Loss: 0.0351, Test Loss: 0.0791, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:58:52 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [5/100], Train Loss: 0.0329, Test Loss: 0.0830, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:59:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [6/100], Train Loss: 0.0309, Test Loss: 0.3751, lr: 0.001\u001b[0m\n",
      "\u001b[32m19:59:42 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [7/100], Train Loss: 0.0298, Test Loss: 0.1011, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:00:07 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [8/100], Train Loss: 0.0280, Test Loss: 0.3445, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:00:32 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [9/100], Train Loss: 0.0263, Test Loss: 0.1243, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:00:57 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [10/100], Train Loss: 0.0247, Test Loss: 0.1443, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:01:22 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [11/100], Train Loss: 0.0246, Test Loss: 0.2160, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:01:47 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [12/100], Train Loss: 0.0223, Test Loss: 0.1984, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:02:12 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [13/100], Train Loss: 0.0245, Test Loss: 0.3832, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:02:37 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [14/100], Train Loss: 0.0214, Test Loss: 0.2169, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:03:02 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [15/100], Train Loss: 0.0208, Test Loss: 0.1168, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:03:27 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [16/100], Train Loss: 0.0257, Test Loss: 0.1679, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:03:52 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [17/100], Train Loss: 0.0184, Test Loss: 0.1641, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:04:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [18/100], Train Loss: 0.0176, Test Loss: 0.1020, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:04:43 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [19/100], Train Loss: 0.0179, Test Loss: 0.1742, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:05:08 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [20/100], Train Loss: 0.0174, Test Loss: 0.0933, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:05:33 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [21/100], Train Loss: 0.0176, Test Loss: 0.1016, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:05:58 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [22/100], Train Loss: 0.0160, Test Loss: 0.2758, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:06:23 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [23/100], Train Loss: 0.0163, Test Loss: 0.2998, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:06:48 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [24/100], Train Loss: 0.0167, Test Loss: 0.3175, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:07:13 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [25/100], Train Loss: 0.0152, Test Loss: 0.2933, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:07:38 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [26/100], Train Loss: 0.0166, Test Loss: 0.4181, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:08:03 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [27/100], Train Loss: 0.0137, Test Loss: 0.2473, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:08:28 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [28/100], Train Loss: 0.0137, Test Loss: 0.5593, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:08:53 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [29/100], Train Loss: 0.0138, Test Loss: 0.1657, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:09:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [30/100], Train Loss: 0.0140, Test Loss: 0.3418, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:09:42 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [31/100], Train Loss: 0.0142, Test Loss: 0.4737, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:10:07 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [32/100], Train Loss: 0.0134, Test Loss: 0.1992, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:10:32 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [33/100], Train Loss: 0.0120, Test Loss: 0.2934, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:10:57 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [34/100], Train Loss: 0.0135, Test Loss: 0.5248, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:11:22 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [35/100], Train Loss: 0.0134, Test Loss: 0.3836, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:11:47 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [36/100], Train Loss: 0.0141, Test Loss: 0.3557, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:12:12 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [37/100], Train Loss: 0.0117, Test Loss: 0.3431, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:12:37 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [38/100], Train Loss: 0.0116, Test Loss: 0.2305, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:13:03 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [39/100], Train Loss: 0.0111, Test Loss: 0.4656, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:13:30 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [40/100], Train Loss: 0.0113, Test Loss: 0.3345, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:13:58 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [41/100], Train Loss: 0.0115, Test Loss: 0.2626, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:14:25 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [42/100], Train Loss: 0.0120, Test Loss: 0.3956, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:14:52 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [43/100], Train Loss: 0.0104, Test Loss: 0.2678, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:15:19 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [44/100], Train Loss: 0.0108, Test Loss: 0.2547, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:15:45 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [45/100], Train Loss: 0.0111, Test Loss: 0.4767, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:16:11 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [46/100], Train Loss: 0.0102, Test Loss: 0.1663, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:16:37 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [47/100], Train Loss: 0.0110, Test Loss: 0.2495, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:17:03 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [48/100], Train Loss: 0.0102, Test Loss: 0.2728, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:17:31 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [49/100], Train Loss: 0.0096, Test Loss: 0.3697, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:17:57 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [50/100], Train Loss: 0.0104, Test Loss: 0.2845, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:18:24 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [51/100], Train Loss: 0.0096, Test Loss: 0.2310, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:18:53 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [52/100], Train Loss: 0.0103, Test Loss: 0.1677, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:19:20 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [53/100], Train Loss: 0.0095, Test Loss: 0.2154, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:19:46 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [54/100], Train Loss: 0.0099, Test Loss: 0.1832, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:20:14 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [55/100], Train Loss: 0.0088, Test Loss: 0.2253, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:20:43 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [56/100], Train Loss: 0.0092, Test Loss: 0.2013, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:21:11 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [57/100], Train Loss: 0.0093, Test Loss: 0.1436, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:21:36 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [58/100], Train Loss: 0.0088, Test Loss: 0.1774, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:22:03 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [59/100], Train Loss: 0.0094, Test Loss: 0.3495, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:22:29 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [60/100], Train Loss: 0.0084, Test Loss: 0.3008, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:23:00 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [61/100], Train Loss: 0.0090, Test Loss: 0.1340, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:23:27 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [62/100], Train Loss: 0.0086, Test Loss: 0.1558, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:23:55 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [63/100], Train Loss: 0.0089, Test Loss: 0.1594, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:24:24 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [64/100], Train Loss: 0.0090, Test Loss: 0.1263, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:24:50 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [65/100], Train Loss: 0.0085, Test Loss: 0.4559, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:25:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [66/100], Train Loss: 0.0088, Test Loss: 0.1645, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:25:45 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [67/100], Train Loss: 0.0088, Test Loss: 0.0969, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:26:11 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [68/100], Train Loss: 0.0086, Test Loss: 0.1221, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:26:36 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [69/100], Train Loss: 0.0087, Test Loss: 0.1355, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:27:01 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [70/100], Train Loss: 0.0080, Test Loss: 0.2286, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:27:27 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [71/100], Train Loss: 0.0083, Test Loss: 0.1381, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:27:52 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [72/100], Train Loss: 0.0089, Test Loss: 0.2694, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:28:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [73/100], Train Loss: 0.0079, Test Loss: 0.1201, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:28:42 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [74/100], Train Loss: 0.0077, Test Loss: 0.0978, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:29:07 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [75/100], Train Loss: 0.0079, Test Loss: 0.2958, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:29:32 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [76/100], Train Loss: 0.0083, Test Loss: 0.1927, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:29:57 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [77/100], Train Loss: 0.0077, Test Loss: 0.2073, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:30:22 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [78/100], Train Loss: 0.0074, Test Loss: 0.1301, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:30:47 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [79/100], Train Loss: 0.0080, Test Loss: 0.1767, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:31:12 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [80/100], Train Loss: 0.0078, Test Loss: 0.2455, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:31:37 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [81/100], Train Loss: 0.0076, Test Loss: 0.1328, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:32:02 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [82/100], Train Loss: 0.0075, Test Loss: 0.2024, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:32:27 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [83/100], Train Loss: 0.0078, Test Loss: 0.2108, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:32:52 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [84/100], Train Loss: 0.0078, Test Loss: 0.1225, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:33:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [85/100], Train Loss: 0.0074, Test Loss: 0.0991, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:33:42 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [86/100], Train Loss: 0.0074, Test Loss: 0.1185, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:34:08 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [87/100], Train Loss: 0.0072, Test Loss: 0.1556, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:34:34 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [88/100], Train Loss: 0.0076, Test Loss: 0.1127, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:35:03 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [89/100], Train Loss: 0.0078, Test Loss: 0.1112, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:35:31 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [90/100], Train Loss: 0.0072, Test Loss: 0.1198, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:35:59 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [91/100], Train Loss: 0.0079, Test Loss: 0.1878, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:36:24 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [92/100], Train Loss: 0.0075, Test Loss: 0.1731, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:36:50 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [93/100], Train Loss: 0.0076, Test Loss: 0.1781, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:37:17 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [94/100], Train Loss: 0.0069, Test Loss: 0.1233, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:37:43 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [95/100], Train Loss: 0.0069, Test Loss: 0.1263, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:38:08 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [96/100], Train Loss: 0.0077, Test Loss: 0.1232, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:38:33 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [97/100], Train Loss: 0.0073, Test Loss: 0.1333, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:39:01 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [98/100], Train Loss: 0.0075, Test Loss: 0.1128, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:39:28 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [99/100], Train Loss: 0.0068, Test Loss: 0.1319, lr: 0.001\u001b[0m\n",
      "\u001b[32m20:39:56 - chessAI - INFO\u001b[0m \u001b[1;37mEpoch [100/100], Train Loss: 0.0076, Test Loss: 0.1439, lr: 0.001\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class ChessEvalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessEvalNet, self).__init__()\n",
    "        \n",
    "        # Initial projection to match channels for residual\n",
    "        self.proj1 = nn.Conv2d(12, 64, kernel_size=1)\n",
    "        self.proj2 = nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.proj3 = nn.Conv2d(128, 256, kernel_size=1)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1a = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv1b = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv2a = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2b = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.conv3a = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3b = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1a = nn.BatchNorm2d(64)\n",
    "        self.bn1b = nn.BatchNorm2d(64)\n",
    "        self.bn2a = nn.BatchNorm2d(128)\n",
    "        self.bn2b = nn.BatchNorm2d(128)\n",
    "        self.bn3a = nn.BatchNorm2d(256)\n",
    "        self.bn3b = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 1)\n",
    "        \n",
    "        self.relu = nn.LeakyReLU(0.1)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First residual block\n",
    "        identity = self.proj1(x)\n",
    "        x = self.relu(self.bn1a(identity))\n",
    "        x = self.relu(self.bn1a(self.conv1a(x)))\n",
    "        x = self.bn1b(self.conv1b(x))\n",
    "        x = self.relu(x + identity)\n",
    "        \n",
    "        # Second residual block\n",
    "        identity = self.proj2(x)\n",
    "        x = self.relu(self.bn2a(self.conv2a(x)))\n",
    "        x = self.bn2b(self.conv2b(x))\n",
    "        x = self.relu(x + identity)\n",
    "        \n",
    "        # Third residual block\n",
    "        identity = self.proj3(x)\n",
    "        x = self.relu(self.bn3a(self.conv3a(x)))\n",
    "        x = self.bn3b(self.conv3b(x))\n",
    "        x = self.relu(x + identity)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = x.view(-1, 256 * 8 * 8)\n",
    "        x = self.dropout(self.relu(self.fc1(x)))\n",
    "        x = self.dropout(self.relu(self.fc2(x)))\n",
    "        x = self.dropout(self.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model and move to device\n",
    "model = ChessEvalNet().to(device)\n",
    "\n",
    "# Convert data to tensors and create DataLoader\n",
    "X_train = torch.FloatTensor(train_X).to(device)\n",
    "y_train = torch.FloatTensor(train_Y).to(device)\n",
    "X_test = torch.FloatTensor(test_X).to(device)\n",
    "y_test = torch.FloatTensor(test_Y).to(device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "# Modified training parameters\n",
    "batch_size = 32  # Increased batch size\n",
    "num_epochs = 100   # More epochs\n",
    "\n",
    "# Create model and move to device\n",
    "model = ChessEvalNet().to(device)\n",
    "\n",
    "# Loss function and optimizer with learning rate scheduler\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "# Update DataLoader with new batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def evaluate_model(model_to_eval, data_loader_eval):\n",
    "    model_to_eval.eval()\n",
    "    eval_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_Y in data_loader_eval:\n",
    "            batch_outputs = model_to_eval(batch_x)\n",
    "            batch_loss = criterion(batch_outputs.squeeze(), batch_Y)\n",
    "            eval_total_loss += batch_loss.item()\n",
    "    return eval_total_loss / len(data_loader_eval)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate losses\n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    test_loss = evaluate_model(model, test_loader)\n",
    "    \n",
    "    # Step the scheduler based on validation loss\n",
    "    scheduler.step(test_loss)  # Add this line\n",
    "    \n",
    "    # Print epoch statistics\n",
    "    logger.info(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, lr: {optimizer.param_groups[0][\"lr\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaca74781f58dff8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T23:54:10.847189Z",
     "start_time": "2024-12-07T23:53:17.264822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mTraining Set Metrics:\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mMAE: 0.2900\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mMSE: 0.1415\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mRMSE: 0.3762\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mR2: -0.5236\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37m\n",
      "Test Set Metrics:\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mMAE: 0.2903\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mMSE: 0.1437\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mRMSE: 0.3790\u001b[0m\n",
      "\u001b[32m20:42:26 - chessAI - INFO\u001b[0m \u001b[1;37mR2: -0.5384\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            outputs = model(batch_X)\n",
    "            all_predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "            all_targets.extend(batch_y.cpu().numpy())\n",
    "            \n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    metrics = {\n",
    "        'MAE': mean_absolute_error(all_targets, all_predictions),\n",
    "        'MSE': mean_squared_error(all_targets, all_predictions),\n",
    "        'RMSE': np.sqrt(mean_squared_error(all_targets, all_predictions)),\n",
    "        'R2': r2_score(all_targets, all_predictions)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for both training and test sets\n",
    "train_metrics = calculate_metrics(model, train_loader)\n",
    "test_metrics = calculate_metrics(model, test_loader)\n",
    "\n",
    "# Print results\n",
    "logger.info(\"Training Set Metrics:\")\n",
    "for metric, value in train_metrics.items():\n",
    "    logger.info(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "logger.info(\"\\nTest Set Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    logger.info(f\"{metric}: {value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
